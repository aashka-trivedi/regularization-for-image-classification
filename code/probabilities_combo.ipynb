{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qpyV-YZacZn"
   },
   "source": [
    "### ResNet50 Model\n",
    "\n",
    "References:\n",
    "\n",
    "https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691\n",
    "\n",
    "https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AdzdlCYNPKYq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import  Rectangle\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D,MaxPooling2D, Flatten,BatchNormalization, Dropout,ZeroPadding2D, AveragePooling2D, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VtrW6zJPaS7n"
   },
   "outputs": [],
   "source": [
    " #Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0, dropout_prob_array=[]):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "  x_skip = x # this will be used for addition with the residual block \n",
    "  f1, f2 = filters\n",
    "  bn = num_batchnorm\n",
    "  drp = num_dropout\n",
    "\n",
    "  #first block \n",
    "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[0])(x)\n",
    "    drp-=1\n",
    "\n",
    "  #second block # bottleneck (but size kept same with padding)\n",
    "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[1])(x)\n",
    "    drp-=1\n",
    "\n",
    "  # third block activation used after adding the input\n",
    "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[2])(x)\n",
    "    drp-=1\n",
    "\n",
    "  # add the input \n",
    "  x = Add()([x, x_skip])\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "  return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0, dropout_prob_array=[]):\n",
    "  '''\n",
    "  here the input size changes''' \n",
    "  x_skip = x\n",
    "  f1, f2 = filters\n",
    "  bn = num_batchnorm\n",
    "  drp = num_dropout\n",
    "\n",
    "  # first block\n",
    "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "  # when s = 2 then it is like downsizing the feature map\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[1])(x)\n",
    "    drp-=1\n",
    "\n",
    "  # second block\n",
    "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[2])(x)\n",
    "    drp-=1\n",
    "\n",
    "  #third block\n",
    "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "\n",
    "  # shortcut \n",
    "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "  x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "  # add \n",
    "  x = Add()([x, x_skip])\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=0, dropout_prob_array = [], num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "  input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "  x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "  bn = num_batchnorm\n",
    "  drp = num_dropout\n",
    "\n",
    "  # 1st stage\n",
    "  # here we perform maxpooling, see the figure above\n",
    "\n",
    "  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "  if bn_pooling:\n",
    "    x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[0])(x)\n",
    "    drp-=1\n",
    "\n",
    "  #2nd stage \n",
    "  # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "  x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "\n",
    "  # 3rd stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "\n",
    "  # 4th stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "\n",
    "  # 5th stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "  x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob, dropout_prob_array=dropout_prob_array)\n",
    "\n",
    "  # ends with average pooling and dense connection\n",
    "\n",
    "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "  x = Flatten()(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob_array[0])(x)\n",
    "    drp-=1\n",
    "  x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "  # define the model \n",
    "\n",
    "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jbcZCB_IQoWX"
   },
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "        self.prev_loss = None\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            print(self.epoch, epoch)\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "            print('end', logs)\n",
    "            \n",
    "        self.epoch += 1\n",
    "#         if (self.prev_loss == None):\n",
    "#             self.prev_loss = logs['loss']\n",
    "#         else:\n",
    "#             delta = np.abs(logs['loss'] - self.prev_loss)\n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PyU1rauccUbZ"
   },
   "outputs": [],
   "source": [
    "def fit_resnet(model, xtrain, ytrain, xtest, ytest, model_name, convergence=False):\n",
    "  \n",
    "    EPOCHS = 500 if convergence else 100     #Change to 200 when running the model\n",
    "    BATCH_SIZE= 256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 15 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    print('Fitting with BS ', BATCH_SIZE)\n",
    "#     es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20) if convergence else None\n",
    "    model.fit(\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=VERBOSITY,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name)]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWnAAeLrPGDW",
    "outputId": "e7d29675-e664-49a9-d668-9a97077ff9e8"
   },
   "outputs": [],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID3, DPCONV3, DPPROB[0.2, 0.5, 0.8]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.8245654106140137, 'accuracy': 0.14552000164985657}\n",
      "15 15\n",
      "end {'loss': 1.0125149488449097, 'accuracy': 0.6394400000572205}\n",
      "30 30\n",
      "end {'loss': 0.6597040891647339, 'accuracy': 0.7688400149345398}\n",
      "45 45\n",
      "end {'loss': 0.43369731307029724, 'accuracy': 0.8476999998092651}\n",
      "Time to reach 0.87 accuracy: 471.8229331970215 s\n",
      "60 60\n",
      "end {'loss': 0.25791946053504944, 'accuracy': 0.9094200134277344}\n",
      "75 75\n",
      "end {'loss': 0.16233089566230774, 'accuracy': 0.9433599710464478}\n",
      "90 90\n",
      "end {'loss': 0.27793821692466736, 'accuracy': 0.9162200093269348}\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.2762 - accuracy: 0.7049\n",
      "Final accuracy 0.7049000263214111 reached in 876.6220529079437\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.5, 0.2, 0.2]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.048828601837158, 'accuracy': 0.3345400094985962}\n",
      "15 15\n",
      "end {'loss': 0.48290780186653137, 'accuracy': 0.8289200067520142}\n",
      "Time to reach 0.87 accuracy: 182.10595512390137 s\n",
      "30 30\n",
      "end {'loss': 0.19206832349300385, 'accuracy': 0.9314799904823303}\n",
      "45 45\n",
      "end {'loss': 0.10060819983482361, 'accuracy': 0.9642599821090698}\n",
      "60 60\n",
      "end {'loss': 0.06857863068580627, 'accuracy': 0.9760599732398987}\n",
      "75 75\n",
      "end {'loss': 0.06387560814619064, 'accuracy': 0.977400004863739}\n",
      "90 90\n",
      "end {'loss': 0.04144774004817009, 'accuracy': 0.98471999168396}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.5918 - accuracy: 0.7495\n",
      "Final accuracy 0.7494999766349792 reached in 845.18665766716\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.2, 0.5, 0.2]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.251905679702759, 'accuracy': 0.2863599956035614}\n",
      "15 15\n",
      "end {'loss': 0.6211085915565491, 'accuracy': 0.7817400097846985}\n",
      "Time to reach 0.87 accuracy: 241.21870756149292 s\n",
      "30 30\n",
      "end {'loss': 0.28758323192596436, 'accuracy': 0.8974800109863281}\n",
      "45 45\n",
      "end {'loss': 0.37140902876853943, 'accuracy': 0.8811799883842468}\n",
      "60 60\n",
      "end {'loss': 0.08334717154502869, 'accuracy': 0.9712399840354919}\n",
      "75 75\n",
      "end {'loss': 0.06914784014225006, 'accuracy': 0.9757000207901001}\n",
      "90 90\n",
      "end {'loss': 0.05496734380722046, 'accuracy': 0.9811800122261047}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.6600 - accuracy: 0.7240\n",
      "Final accuracy 0.7239999771118164 reached in 843.4118311405182\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.5, 0.5, 0.2]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.2300336360931396, 'accuracy': 0.27733999490737915}\n",
      "15 15\n",
      "end {'loss': 0.6841733455657959, 'accuracy': 0.7555599808692932}\n",
      "30 30\n",
      "end {'loss': 0.34185341000556946, 'accuracy': 0.8782600164413452}\n",
      "Time to reach 0.87 accuracy: 265.5628159046173 s\n",
      "45 45\n",
      "end {'loss': 0.16725322604179382, 'accuracy': 0.9394999742507935}\n",
      "60 60\n",
      "end {'loss': 0.09972432255744934, 'accuracy': 0.9649199843406677}\n",
      "75 75\n",
      "end {'loss': 0.09617891907691956, 'accuracy': 0.9658600091934204}\n",
      "90 90\n",
      "end {'loss': 0.07499060779809952, 'accuracy': 0.9738199710845947}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.4778 - accuracy: 0.7367\n",
      "Final accuracy 0.7366999983787537 reached in 841.7836611270905\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.1, 0.2, 0.3]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.036231517791748, 'accuracy': 0.34696000814437866}\n",
      "15 15\n",
      "end {'loss': 0.423814058303833, 'accuracy': 0.8488600254058838}\n",
      "Time to reach 0.87 accuracy: 154.57555174827576 s\n",
      "30 30\n",
      "end {'loss': 0.14427828788757324, 'accuracy': 0.949999988079071}\n",
      "45 45\n",
      "end {'loss': 0.10555525124073029, 'accuracy': 0.9622799754142761}\n",
      "60 60\n",
      "end {'loss': 0.06347672641277313, 'accuracy': 0.9778599739074707}\n",
      "75 75\n",
      "end {'loss': 0.04793379083275795, 'accuracy': 0.9829800128936768}\n",
      "90 90\n",
      "end {'loss': 0.03961856663227081, 'accuracy': 0.9864199757575989}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.3973 - accuracy: 0.7710\n",
      "Final accuracy 0.7710000276565552 reached in 834.3750269412994\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.3, 0.2, 0.1]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.893539547920227, 'accuracy': 0.3778400123119354}\n",
      "15 15\n",
      "end {'loss': 0.35341691970825195, 'accuracy': 0.8756999969482422}\n",
      "Time to reach 0.87 accuracy: 137.68410849571228 s\n",
      "30 30\n",
      "end {'loss': 0.16500940918922424, 'accuracy': 0.9448800086975098}\n",
      "45 45\n",
      "end {'loss': 0.07625328004360199, 'accuracy': 0.9733999967575073}\n",
      "60 60\n",
      "end {'loss': 0.2895110547542572, 'accuracy': 0.9015600085258484}\n",
      "75 75\n",
      "end {'loss': 0.04255770891904831, 'accuracy': 0.9851999878883362}\n",
      "90 90\n",
      "end {'loss': 0.039126232266426086, 'accuracy': 0.9866200089454651}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.4110 - accuracy: 0.7606\n",
      "Final accuracy 0.7605999708175659 reached in 829.1241753101349\n"
     ]
    }
   ],
   "source": [
    "dropout_prob_array=[\n",
    "    [0.2,0.5,0.8],\n",
    "    [0.5,0.2,0.2],\n",
    "    [0.2,0.5,0.2],\n",
    "    [0.5,0.5,0.2],\n",
    "    [0.1,0.2,0.3],\n",
    "    [0.3,0.2,0.1],\n",
    "]\n",
    "dp = 3\n",
    "bn = 2\n",
    "\n",
    "for arr in dropout_prob_array:\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{}'.format(bn, dp, dp, arr))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}'.format(bn, dp, dp, str(arr))\n",
    "    resnet_model = resnet50(\n",
    "        num_batchnorm=bn,\n",
    "        bn_pooling=True,\n",
    "        num_dropout_conv=dp,\n",
    "        num_dropout_id=dp,\n",
    "#         dropout_prob=prob, \n",
    "        dropout_prob_array=arr\n",
    "    )\n",
    "    tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID3, DPCONV3, DPPROB[0.1, 0.15, 0.25]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.891187071800232, 'accuracy': 0.38067999482154846}\n",
      "15 15\n",
      "end {'loss': 0.3409976065158844, 'accuracy': 0.8772799968719482}\n",
      "Time to reach 0.87 accuracy: 140.53654289245605 s\n",
      "30 30\n",
      "end {'loss': 0.1258680820465088, 'accuracy': 0.956279993057251}\n",
      "45 45\n",
      "end {'loss': 0.09529784321784973, 'accuracy': 0.9682599902153015}\n",
      "60 60\n",
      "end {'loss': 0.048838019371032715, 'accuracy': 0.9841600060462952}\n",
      "75 75\n",
      "end {'loss': 0.05079131945967674, 'accuracy': 0.9831200242042542}\n",
      "90 90\n",
      "end {'loss': 0.0386514887213707, 'accuracy': 0.9864400029182434}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.4404 - accuracy: 0.7506\n",
      "Final accuracy 0.7505999803543091 reached in 846.3317098617554\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.05, 0.1, 0.15]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9078837633132935, 'accuracy': 0.39921998977661133}\n",
      "Time to reach 0.87 accuracy: 104.93711543083191 s\n",
      "15 15\n",
      "end {'loss': 0.21184292435646057, 'accuracy': 0.9255399703979492}\n",
      "30 30\n",
      "end {'loss': 0.0867728590965271, 'accuracy': 0.9700999855995178}\n",
      "45 45\n",
      "end {'loss': 0.052121665328741074, 'accuracy': 0.9821599721908569}\n",
      "60 60\n",
      "end {'loss': 0.04050945118069649, 'accuracy': 0.9861999750137329}\n",
      "75 75\n",
      "end {'loss': 0.03289877995848656, 'accuracy': 0.9890999794006348}\n",
      "90 90\n",
      "end {'loss': 0.028339840471744537, 'accuracy': 0.990339994430542}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.0209 - accuracy: 0.7305\n",
      "Final accuracy 0.7304999828338623 reached in 842.4940419197083\n",
      "Training BN2, DPID3, DPCONV3, DPPROB[0.09, 0.29, 0.59]\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.4573168754577637, 'accuracy': 0.2281399965286255}\n",
      "15 15\n",
      "end {'loss': 0.6267316937446594, 'accuracy': 0.7795199751853943}\n",
      "Time to reach 0.87 accuracy: 234.25644850730896 s\n",
      "30 30\n",
      "end {'loss': 0.2995627820491791, 'accuracy': 0.8952800035476685}\n",
      "45 45\n",
      "end {'loss': 0.1898457258939743, 'accuracy': 0.9348800182342529}\n",
      "60 60\n",
      "end {'loss': 0.08732405304908752, 'accuracy': 0.969980001449585}\n",
      "75 75\n",
      "end {'loss': 0.08449073880910873, 'accuracy': 0.9709799885749817}\n",
      "90 90\n",
      "end {'loss': 0.050081487745046616, 'accuracy': 0.9828400015830994}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.3048 - accuracy: 0.7435\n",
      "Final accuracy 0.7434999942779541 reached in 865.9739141464233\n"
     ]
    }
   ],
   "source": [
    "dropout_prob_array=[\n",
    "    [0.1,0.15,0.25],\n",
    "    [0.05, 0.1, 0.15],\n",
    "    [0.09, 0.29, 0.59],\n",
    "]\n",
    "dp = 3\n",
    "bn = 2\n",
    "\n",
    "for arr in dropout_prob_array:\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{}'.format(bn, dp, dp, arr))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}'.format(bn, dp, dp, str(arr))\n",
    "    resnet_model = resnet50(\n",
    "        num_batchnorm=bn,\n",
    "        bn_pooling=True,\n",
    "        num_dropout_conv=dp,\n",
    "        num_dropout_id=dp,\n",
    "#         dropout_prob=prob, \n",
    "        dropout_prob_array=arr\n",
    "    )\n",
    "    tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IDLS Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
