{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed633f36",
   "metadata": {},
   "source": [
    "### ResNet50 Model\n",
    "\n",
    "References:\n",
    "\n",
    "https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691\n",
    "\n",
    "https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb\n",
    "\n",
    "https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddb928",
   "metadata": {},
   "source": [
    "Batch Size: 256\n",
    "\n",
    "Number of Dropout Layers: 2\n",
    "\n",
    "Number of BatchNorm Layers: 2\n",
    "\n",
    "Dropout Probability: 0.2\n",
    "\n",
    "Data Augmentation: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0589ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import  Rectangle\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D,MaxPooling2D, Flatten,BatchNormalization, Dropout,ZeroPadding2D, AveragePooling2D, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed855434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## taken from class resource posted on Campuswire\n",
    "## https://medium.com/@ombelinelag/cutout-regularization-for-cnns-62670d86bc33\n",
    "def apply_mask(image, size=12, n_squares=1):\n",
    "    h, w, channels = image.shape\n",
    "    new_image = np.copy(image)\n",
    "    for _ in range(n_squares):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        y1 = np.clip(y - size // 2, 0, h)\n",
    "        y2 = np.clip(y + size // 2, 0, h)\n",
    "        x1 = np.clip(x - size // 2, 0, w)\n",
    "        x2 = np.clip(x + size // 2, 0, w)\n",
    "        new_image[y1:y2,x1:x2,:] = 0\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffeea38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Model\n",
    "#Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=0, num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "    input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    if bn_pooling:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "    x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f10b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "        self.prev_loss = None\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            print(self.epoch, epoch)\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "            print('end', logs)\n",
    "            \n",
    "        self.epoch += 1\n",
    "#         if (self.prev_loss == None):\n",
    "#             self.prev_loss = logs['loss']\n",
    "#         else:\n",
    "#             delta = np.abs(logs['loss'] - self.prev_loss)\n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f685d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23b1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6490e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x, y, epochs, m, batch_size, augment=None):\n",
    "    for _ in range(epochs):\n",
    "        n = x.shape[0]\n",
    "        reorder = np.random.permutation(n)\n",
    "        cursor = 0\n",
    "        while cursor + batch_size < x.shape[0]:\n",
    "            x_batch = x[reorder[cursor:cursor+batch_size]]\n",
    "            y_batch = y[reorder[cursor:cursor+batch_size]]\n",
    "            if augment != None:\n",
    "                yield np.array([augment(xx) for xx in x_batch for rep in range(m)]), np.array([yy for yy in y_batch for rep in range(m)])\n",
    "            else:\n",
    "                yield x_batch, y_batch\n",
    "            cursor += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a0f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3a21498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_resnet_dataaug(model, xtrain, ytrain, xtest, ytest, model_name, m=0, convergence=False):\n",
    "  \n",
    "    EPOCHS = 500 if convergence else 100    \n",
    "    #EPOCHS=10\n",
    "    BATCH_SIZE= 256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 25 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    print('Fitting with BS ', BATCH_SIZE)\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20) if convergence else []\n",
    "    hist = model.fit_generator(\n",
    "      batch_generator(\n",
    "          xtrain,\n",
    "          ytrain,\n",
    "          m=m,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS, \n",
    "          augment=apply_mask\n",
    "      ),\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch=np.floor(xtrain.shape[0]/BATCH_SIZE),\n",
    "      verbose=VERBOSITY,\n",
    "      callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name), es]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21aee915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 2 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.0387589931488037, 'accuracy': 0.3445412516593933}\n",
      "15 15\n",
      "end {'loss': 0.4901897609233856, 'accuracy': 0.8265925645828247}\n",
      "Time to reach 0.87 accuracy: 320.63774585723877 s\n",
      "30 30\n",
      "end {'loss': 0.20758061110973358, 'accuracy': 0.9280849099159241}\n",
      "45 45\n",
      "end {'loss': 0.12475817650556564, 'accuracy': 0.956560492515564}\n",
      "60 60\n",
      "end {'loss': 0.09590400010347366, 'accuracy': 0.9673577547073364}\n",
      "75 75\n",
      "end {'loss': 0.07059597969055176, 'accuracy': 0.9755709171295166}\n",
      "90 90\n",
      "end {'loss': 0.09564609080553055, 'accuracy': 0.9691706895828247}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.1385 - accuracy: 0.7899\n",
      "Final accuracy 0.789900004863739 reached in 1500.6697494983673\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 4 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9135963916778564, 'accuracy': 0.36420774459838867}\n",
      "15 15\n",
      "end {'loss': 0.3716733455657959, 'accuracy': 0.8667367696762085}\n",
      "Time to reach 0.87 accuracy: 463.3434166908264 s\n",
      "30 30\n",
      "end {'loss': 0.12493204325437546, 'accuracy': 0.9563801884651184}\n",
      "45 45\n",
      "end {'loss': 0.07337363064289093, 'accuracy': 0.9746243953704834}\n",
      "60 60\n",
      "end {'loss': 0.08505174517631531, 'accuracy': 0.973086953163147}\n",
      "75 75\n",
      "end {'loss': 0.03835435211658478, 'accuracy': 0.9869140386581421}\n",
      "90 90\n",
      "end {'loss': 0.035830676555633545, 'accuracy': 0.9877303838729858}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.4337 - accuracy: 0.7709\n",
      "Final accuracy 0.7709000110626221 reached in 2691.5938482284546\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 8 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.913364052772522, 'accuracy': 0.36994192004203796}\n",
      "Time to reach 0.87 accuracy: 634.1903426647186 s\n",
      "15 15\n",
      "end {'loss': 0.24871206283569336, 'accuracy': 0.9113581776618958}\n",
      "30 30\n",
      "end {'loss': 0.07730937749147415, 'accuracy': 0.9735050797462463}\n",
      "45 45\n",
      "end {'loss': 0.04603487253189087, 'accuracy': 0.9841771721839905}\n",
      "60 60\n",
      "end {'loss': 0.03511815145611763, 'accuracy': 0.9880508780479431}\n",
      "75 75\n",
      "end {'loss': 0.021872887387871742, 'accuracy': 0.9924028515815735}\n",
      "90 90\n",
      "end {'loss': 0.022959504276514053, 'accuracy': 0.9921774864196777}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.3999 - accuracy: 0.7863\n",
      "Final accuracy 0.786300003528595 reached in 4887.652304410934\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 16 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.8197298049926758, 'accuracy': 0.39074018597602844}\n",
      "Time to reach 0.87 accuracy: 1174.231184720993 s\n",
      "15 15\n",
      "end {'loss': 0.17487481236457825, 'accuracy': 0.9379319548606873}\n",
      "30 30\n",
      "end {'loss': 0.04987266659736633, 'accuracy': 0.9827423691749573}\n",
      "45 45\n",
      "end {'loss': 0.02892545610666275, 'accuracy': 0.9899464249610901}\n",
      "60 60\n",
      "end {'loss': 0.023060008883476257, 'accuracy': 0.9921336770057678}\n",
      "75 75\n",
      "end {'loss': 0.018297340720891953, 'accuracy': 0.9937299489974976}\n",
      "90 90\n",
      "end {'loss': 0.009595423936843872, 'accuracy': 0.9967147707939148}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.6029 - accuracy: 0.7898\n",
      "Final accuracy 0.7897999882698059 reached in 9786.10599064827\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 32 images\n",
      "Fitting with BS  256\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8192,2048,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Resnet50/average_pooling2d_8/AvgPool (defined at <ipython-input-16-38fde4195acf>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_262251]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a15a601e8114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batchnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_pooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dropout_conv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dropout_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_resnet_dataaug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final accuracy {} reached in {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-38fde4195acf>\u001b[0m in \u001b[0;36mfit_resnet_dataaug\u001b[0;34m(model, xtrain, ytrain, xtest, ytest, model_name, m, convergence)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSITY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimeToAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_ckpt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH_CKPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8192,2048,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Resnet50/average_pooling2d_8/AvgPool (defined at <ipython-input-16-38fde4195acf>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_262251]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "dp = 2\n",
    "prob = 0.2\n",
    "bn = 2\n",
    "for m in [2, 4, 8, 16, 32, 64]:\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images'.format(bn, dp, dp, prob, m))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}'.format(bn, dp, dp, prob, m)\n",
    "    resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "    tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bacterial-softball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ms=[2,4,8,16]\n",
    "\n",
    "values = [\n",
    "    0.789900004863739,\n",
    "    0.7709000110626221,\n",
    "    0.786300003528595,\n",
    "    0.7897999882698059\n",
    "]\n",
    "\n",
    "\n",
    "training_times = [\n",
    "    1500.6697494983673,\n",
    "    2691.5938482284546,\n",
    "    4887.652304410934,\n",
    "    9786.10599064827\n",
    "]\n",
    "\n",
    "plt.plot(range(len(values)), values)\n",
    "plt.xticks(range(len(values)), ms)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Cutout images per batch')\n",
    "\n",
    "plt.savefig('cutout_exp_accuracies.jpg', bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "similar-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(training_times)), training_times)\n",
    "plt.xticks(range(len(training_times)), ms)\n",
    "plt.ylabel('Training time')\n",
    "plt.xlabel('Cutout images per batch')\n",
    "\n",
    "plt.savefig('cutout_exp_times.jpg', bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea65d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 2 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.0145556926727295, 'accuracy': 0.3443509638309479}\n",
      "Time to reach 0.87 accuracy: 337.87398171424866 s\n",
      "25 25\n",
      "end {'loss': 0.2765456438064575, 'accuracy': 0.900971531867981}\n",
      "50 50\n",
      "end {'loss': 0.11017855256795883, 'accuracy': 0.9616686701774597}\n",
      "75 75\n",
      "end {'loss': 0.16221535205841064, 'accuracy': 0.944451093673706}\n",
      "100 100\n",
      "end {'loss': 0.057838018983602524, 'accuracy': 0.9803485870361328}\n",
      "125 125\n",
      "end {'loss': 0.04218747466802597, 'accuracy': 0.9854066371917725}\n",
      "150 150\n",
      "end {'loss': 0.03655320778489113, 'accuracy': 0.9875300526618958}\n",
      "175 175\n",
      "end {'loss': 0.03279444947838783, 'accuracy': 0.9886217713356018}\n",
      "200 200\n",
      "end {'loss': 0.02311616763472557, 'accuracy': 0.9924378991127014}\n",
      "225 225\n",
      "end {'loss': 0.02629760093986988, 'accuracy': 0.9911458492279053}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.4342 - accuracy: 0.7766\n",
      "Final accuracy 0.7766000032424927 reached in 3495.9596168994904\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 16 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.8686814308166504, 'accuracy': 0.3844626545906067}\n",
      "Time to reach 0.87 accuracy: 1143.236328125 s\n",
      "25 25\n",
      "end {'loss': 0.06201820820569992, 'accuracy': 0.9784718155860901}\n",
      "50 50\n",
      "end {'loss': 0.025336982682347298, 'accuracy': 0.9913273453712463}\n",
      "75 75\n",
      "end {'loss': 0.011995816603302956, 'accuracy': 0.9958921670913696}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.6300 - accuracy: 0.7818\n",
      "Final accuracy 0.7817999720573425 reached in 9135.45040512085\n"
     ]
    }
   ],
   "source": [
    "dp = 2\n",
    "prob = 0.2\n",
    "bn = 2\n",
    "\n",
    "for m in [2, 16]:\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images -- convergence'.format(bn, dp, dp, prob, m))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}__convergence'.format(bn, dp, dp, prob, m)\n",
    "    resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "    tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624505c",
   "metadata": {},
   "source": [
    "## Non-Uniform Dropout Probability\n",
    "\n",
    "Testing the effect of varying the dropout probability across layers. \n",
    "\n",
    "Batch Size: 256\n",
    "\n",
    "Number of Dropout Layers: 3\n",
    "\n",
    "Number of BatchNorm Layers: 2\n",
    "\n",
    "Dropout Probability: [0.1, 0.2, 0.3]\n",
    "\n",
    "Data Augmentation: true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930c895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Model\n",
    "#Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = [0,0,0]):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[0])(x)\n",
    "        drp-=1\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[1])(x)\n",
    "        drp-=1\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[2])(x)\n",
    "        drp-=1\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = [0,0,0]):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[0])(x)\n",
    "        drp-=1\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[1])(x)\n",
    "        drp-=1\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=[0,0,0], num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "    input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    if bn_pooling:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[0])(x)\n",
    "        drp-=1\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[1])(x)\n",
    "        drp-=1\n",
    "    x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ee7e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "        self.prev_loss = None\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            print(self.epoch, epoch)\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "            print('end', logs)\n",
    "            \n",
    "        self.epoch += 1\n",
    "#         if (self.prev_loss == None):\n",
    "#             self.prev_loss = logs['loss']\n",
    "#         else:\n",
    "#             delta = np.abs(logs['loss'] - self.prev_loss)\n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a200fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3a17fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_resnet_dataaug(model, xtrain, ytrain, xtest, ytest, model_name, m=0, convergence=False):\n",
    "  \n",
    "    EPOCHS = 500 if convergence else 100    \n",
    "    #EPOCHS=10\n",
    "    BATCH_SIZE= 256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 25 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    print('Fitting with BS ', BATCH_SIZE)\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20) if convergence else []\n",
    "    hist = model.fit_generator(\n",
    "      batch_generator(\n",
    "          xtrain,\n",
    "          ytrain,\n",
    "          m=m,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS, \n",
    "          augment=apply_mask\n",
    "      ),\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch=np.floor(xtrain.shape[0]/BATCH_SIZE),\n",
    "      verbose=VERBOSITY,\n",
    "      callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name), es]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c613699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID3, DPCONV3, DPPROB[0.1, 0.2, 0.3] with cutout regularization augmenting with 2 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9849753379821777, 'accuracy': 0.34402042627334595}\n",
      "Time to reach 0.87 accuracy: 353.8247067928314 s\n",
      "25 25\n",
      "end {'loss': 0.2959114611148834, 'accuracy': 0.8942908644676208}\n",
      "50 50\n",
      "end {'loss': 0.33701395988464355, 'accuracy': 0.885667085647583}\n",
      "75 75\n",
      "end {'loss': 0.08119558542966843, 'accuracy': 0.9720953702926636}\n",
      "100 100\n",
      "end {'loss': 0.06175059825181961, 'accuracy': 0.9788361191749573}\n",
      "125 125\n",
      "end {'loss': 0.04832686856389046, 'accuracy': 0.9833633899688721}\n",
      "150 150\n",
      "end {'loss': 0.03850960731506348, 'accuracy': 0.9867788553237915}\n",
      "175 175\n",
      "end {'loss': 0.03378571569919586, 'accuracy': 0.9882411956787109}\n",
      "200 200\n",
      "end {'loss': 0.027928432449698448, 'accuracy': 0.9903044700622559}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.3007 - accuracy: 0.7751\n",
      "Final accuracy 0.7750999927520752 reached in 3290.1112921237946\n"
     ]
    }
   ],
   "source": [
    "dp = 3\n",
    "prob = [0.1,0.2,0.3]\n",
    "bn = 2\n",
    "m=2\n",
    "\n",
    "print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images -- convergence'.format(bn, dp, dp, prob, m))\n",
    "model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}__convergence'.format(bn, dp, dp, prob, m)\n",
    "resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab78af9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 0.0274589154869318, 'accuracy': 0.990705132484436}\n",
      "Time to reach 0.87 accuracy: 21.379766941070557 s\n",
      "25 25\n",
      "end {'loss': 0.023547060787677765, 'accuracy': 0.9918569922447205}\n",
      "50 50\n",
      "end {'loss': 0.020078452304005623, 'accuracy': 0.9932191371917725}\n",
      "75 75\n",
      "end {'loss': 0.018917160108685493, 'accuracy': 0.9936298131942749}\n",
      "100 100\n",
      "end {'loss': 0.017210695892572403, 'accuracy': 0.9941005706787109}\n",
      "125 125\n",
      "end {'loss': 0.016712816432118416, 'accuracy': 0.9943810105323792}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.4501 - accuracy: 0.7819\n",
      "Final accuracy 0.7818999886512756 reached in 2109.7273614406586\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check on Early Stopping\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d31b6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID3, DPCONV3, DPPROB[0.1, 0.2, 0.3] with cutout regularization augmenting with 8 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9892884492874146, 'accuracy': 0.34222254157066345}\n",
      "Time to reach 0.87 accuracy: 706.7439835071564 s\n",
      "25 25\n",
      "end {'loss': 0.10552433878183365, 'accuracy': 0.9628405570983887}\n",
      "50 50\n",
      "end {'loss': 0.1645677089691162, 'accuracy': 0.9427208304405212}\n",
      "75 75\n",
      "end {'loss': 0.028589993715286255, 'accuracy': 0.990349531173706}\n",
      "100 100\n",
      "end {'loss': 0.019782431423664093, 'accuracy': 0.9932291507720947}\n",
      "125 125\n",
      "end {'loss': 0.01572389528155327, 'accuracy': 0.9947065114974976}\n",
      "150 150\n",
      "end {'loss': 0.010338203981518745, 'accuracy': 0.9964869022369385}\n",
      "175 175\n",
      "end {'loss': 0.010637978091835976, 'accuracy': 0.9964167475700378}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.5902 - accuracy: 0.7774\n",
      "Final accuracy 0.777400016784668 reached in 8916.544905424118\n"
     ]
    }
   ],
   "source": [
    "dp = 3\n",
    "prob = [0.1,0.2,0.3]\n",
    "bn = 2\n",
    "m=8\n",
    "\n",
    "print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images -- convergence'.format(bn, dp, dp, prob, m))\n",
    "model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}__convergence'.format(bn, dp, dp, prob, m)\n",
    "resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98916b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 0.01137738861143589, 'accuracy': 0.9963091015815735}\n",
      "Time to reach 0.87 accuracy: 55.01160931587219 s\n",
      "25 25\n",
      "end {'loss': 0.009120335802435875, 'accuracy': 0.9968299269676208}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.7476 - accuracy: 0.7665\n",
      "Final accuracy 0.7664999961853027 reached in 1753.1628396511078\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check on Early Stopping\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56720aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
