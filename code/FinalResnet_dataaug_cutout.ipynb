{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed633f36",
   "metadata": {},
   "source": [
    "### ResNet50 Model\n",
    "\n",
    "References:\n",
    "\n",
    "https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691\n",
    "\n",
    "https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb\n",
    "\n",
    "https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddb928",
   "metadata": {},
   "source": [
    "Batch Size: 256\n",
    "\n",
    "Number of Dropout Layers: 2\n",
    "\n",
    "Number of BatchNorm Layers: 2\n",
    "\n",
    "Dropout Probability: 0.2\n",
    "\n",
    "Data Augmentation: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0589ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import  Rectangle\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D,MaxPooling2D, Flatten,BatchNormalization, Dropout,ZeroPadding2D, AveragePooling2D, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed855434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## taken from class resource posted on Campuswire\n",
    "## https://medium.com/@ombelinelag/cutout-regularization-for-cnns-62670d86bc33\n",
    "def apply_mask(image, size=12, n_squares=1):\n",
    "    h, w, channels = image.shape\n",
    "    new_image = np.copy(image)\n",
    "    for _ in range(n_squares):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        y1 = np.clip(y - size // 2, 0, h)\n",
    "        y2 = np.clip(y + size // 2, 0, h)\n",
    "        x1 = np.clip(x - size // 2, 0, w)\n",
    "        x2 = np.clip(x + size // 2, 0, w)\n",
    "        new_image[y1:y2,x1:x2,:] = 0\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffeea38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Model\n",
    "#Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=0, num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "    input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    if bn_pooling:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "    x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f10b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "        self.prev_loss = None\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            print(self.epoch, epoch)\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "            print('end', logs)\n",
    "            \n",
    "        self.epoch += 1\n",
    "#         if (self.prev_loss == None):\n",
    "#             self.prev_loss = logs['loss']\n",
    "#         else:\n",
    "#             delta = np.abs(logs['loss'] - self.prev_loss)\n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f685d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23b1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6490e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x, y, epochs, m, batch_size, augment=None):\n",
    "    for _ in range(epochs):\n",
    "        n = x.shape[0]\n",
    "        reorder = np.random.permutation(n)\n",
    "        cursor = 0\n",
    "        while cursor + batch_size < x.shape[0]:\n",
    "            x_batch = x[reorder[cursor:cursor+batch_size]]\n",
    "            y_batch = y[reorder[cursor:cursor+batch_size]]\n",
    "            if augment != None:\n",
    "                yield np.array([augment(xx) for xx in x_batch for rep in range(m)]), np.array([yy for yy in y_batch for rep in range(m)])\n",
    "            else:\n",
    "                yield x_batch, y_batch\n",
    "            cursor += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a0f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3a21498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_resnet_dataaug(model, xtrain, ytrain, xtest, ytest, model_name, m=0, convergence=False):\n",
    "  \n",
    "    EPOCHS = 500 if convergence else 100    \n",
    "    #EPOCHS=10\n",
    "    BATCH_SIZE= 256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 25 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    print('Fitting with BS ', BATCH_SIZE)\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20) if convergence else []\n",
    "    hist = model.fit_generator(\n",
    "      batch_generator(\n",
    "          xtrain,\n",
    "          ytrain,\n",
    "          m=m,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS, \n",
    "          augment=apply_mask\n",
    "      ),\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch=np.floor(xtrain.shape[0]/BATCH_SIZE),\n",
    "      verbose=VERBOSITY,\n",
    "      callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name), es]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21aee915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 2 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.0387589931488037, 'accuracy': 0.3445412516593933}\n",
      "15 15\n",
      "end {'loss': 0.4901897609233856, 'accuracy': 0.8265925645828247}\n",
      "Time to reach 0.87 accuracy: 320.63774585723877 s\n",
      "30 30\n",
      "end {'loss': 0.20758061110973358, 'accuracy': 0.9280849099159241}\n",
      "45 45\n",
      "end {'loss': 0.12475817650556564, 'accuracy': 0.956560492515564}\n",
      "60 60\n",
      "end {'loss': 0.09590400010347366, 'accuracy': 0.9673577547073364}\n",
      "75 75\n",
      "end {'loss': 0.07059597969055176, 'accuracy': 0.9755709171295166}\n",
      "90 90\n",
      "end {'loss': 0.09564609080553055, 'accuracy': 0.9691706895828247}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.1385 - accuracy: 0.7899\n",
      "Final accuracy 0.789900004863739 reached in 1500.6697494983673\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 4 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9135963916778564, 'accuracy': 0.36420774459838867}\n",
      "15 15\n",
      "end {'loss': 0.3716733455657959, 'accuracy': 0.8667367696762085}\n",
      "Time to reach 0.87 accuracy: 463.3434166908264 s\n",
      "30 30\n",
      "end {'loss': 0.12493204325437546, 'accuracy': 0.9563801884651184}\n",
      "45 45\n",
      "end {'loss': 0.07337363064289093, 'accuracy': 0.9746243953704834}\n",
      "60 60\n",
      "end {'loss': 0.08505174517631531, 'accuracy': 0.973086953163147}\n",
      "75 75\n",
      "end {'loss': 0.03835435211658478, 'accuracy': 0.9869140386581421}\n",
      "90 90\n",
      "end {'loss': 0.035830676555633545, 'accuracy': 0.9877303838729858}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.4337 - accuracy: 0.7709\n",
      "Final accuracy 0.7709000110626221 reached in 2691.5938482284546\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 8 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.913364052772522, 'accuracy': 0.36994192004203796}\n",
      "Time to reach 0.87 accuracy: 634.1903426647186 s\n",
      "15 15\n",
      "end {'loss': 0.24871206283569336, 'accuracy': 0.9113581776618958}\n",
      "30 30\n",
      "end {'loss': 0.07730937749147415, 'accuracy': 0.9735050797462463}\n",
      "45 45\n",
      "end {'loss': 0.04603487253189087, 'accuracy': 0.9841771721839905}\n",
      "60 60\n",
      "end {'loss': 0.03511815145611763, 'accuracy': 0.9880508780479431}\n",
      "75 75\n",
      "end {'loss': 0.021872887387871742, 'accuracy': 0.9924028515815735}\n",
      "90 90\n",
      "end {'loss': 0.022959504276514053, 'accuracy': 0.9921774864196777}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.3999 - accuracy: 0.7863\n",
      "Final accuracy 0.786300003528595 reached in 4887.652304410934\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 16 images\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.8197298049926758, 'accuracy': 0.39074018597602844}\n",
      "Time to reach 0.87 accuracy: 1174.231184720993 s\n",
      "15 15\n",
      "end {'loss': 0.17487481236457825, 'accuracy': 0.9379319548606873}\n",
      "30 30\n",
      "end {'loss': 0.04987266659736633, 'accuracy': 0.9827423691749573}\n",
      "45 45\n",
      "end {'loss': 0.02892545610666275, 'accuracy': 0.9899464249610901}\n",
      "60 60\n",
      "end {'loss': 0.023060008883476257, 'accuracy': 0.9921336770057678}\n",
      "75 75\n",
      "end {'loss': 0.018297340720891953, 'accuracy': 0.9937299489974976}\n",
      "90 90\n",
      "end {'loss': 0.009595423936843872, 'accuracy': 0.9967147707939148}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.6029 - accuracy: 0.7898\n",
      "Final accuracy 0.7897999882698059 reached in 9786.10599064827\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 32 images\n",
      "Fitting with BS  256\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8192,2048,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Resnet50/average_pooling2d_8/AvgPool (defined at <ipython-input-16-38fde4195acf>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_262251]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a15a601e8114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batchnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_pooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dropout_conv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dropout_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_resnet_dataaug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final accuracy {} reached in {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-38fde4195acf>\u001b[0m in \u001b[0;36mfit_resnet_dataaug\u001b[0;34m(model, xtrain, ytrain, xtest, ytest, model_name, m, convergence)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSITY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimeToAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_ckpt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH_CKPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8192,2048,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Resnet50/average_pooling2d_8/AvgPool (defined at <ipython-input-16-38fde4195acf>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_262251]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "dp = 2\n",
    "prob = 0.2\n",
    "bn = 2\n",
    "for m in [2, 4, 8, 16, 32, 64]:\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images'.format(bn, dp, dp, prob, m))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}'.format(bn, dp, dp, prob, m)\n",
    "    resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "    tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea65d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 2 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 2.0145556926727295, 'accuracy': 0.3443509638309479}\n",
      "Time to reach 0.87 accuracy: 337.87398171424866 s\n",
      "25 25\n",
      "end {'loss': 0.2765456438064575, 'accuracy': 0.900971531867981}\n",
      "50 50\n",
      "end {'loss': 0.11017855256795883, 'accuracy': 0.9616686701774597}\n",
      "75 75\n",
      "end {'loss': 0.16221535205841064, 'accuracy': 0.944451093673706}\n",
      "100 100\n",
      "end {'loss': 0.057838018983602524, 'accuracy': 0.9803485870361328}\n",
      "125 125\n",
      "end {'loss': 0.04218747466802597, 'accuracy': 0.9854066371917725}\n",
      "150 150\n",
      "end {'loss': 0.03655320778489113, 'accuracy': 0.9875300526618958}\n",
      "175 175\n",
      "end {'loss': 0.03279444947838783, 'accuracy': 0.9886217713356018}\n",
      "200 200\n",
      "end {'loss': 0.02311616763472557, 'accuracy': 0.9924378991127014}\n",
      "225 225\n",
      "end {'loss': 0.02629760093986988, 'accuracy': 0.9911458492279053}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.4342 - accuracy: 0.7766\n",
      "Final accuracy 0.7766000032424927 reached in 3495.9596168994904\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2 with cutout regularization augmenting with 16 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.8686814308166504, 'accuracy': 0.3844626545906067}\n",
      "Time to reach 0.87 accuracy: 1143.236328125 s\n",
      "25 25\n",
      "end {'loss': 0.06201820820569992, 'accuracy': 0.9784718155860901}\n",
      "50 50\n",
      "end {'loss': 0.025336982682347298, 'accuracy': 0.9913273453712463}\n",
      "75 75\n",
      "end {'loss': 0.011995816603302956, 'accuracy': 0.9958921670913696}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.6300 - accuracy: 0.7818\n",
      "Final accuracy 0.7817999720573425 reached in 9135.45040512085\n"
     ]
    }
   ],
   "source": [
    "dp = 2\n",
    "prob = 0.2\n",
    "bn = 2\n",
    "\n",
    "for m in [2, 16]:\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images -- convergence'.format(bn, dp, dp, prob, m))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}__convergence'.format(bn, dp, dp, prob, m)\n",
    "    resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "    tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624505c",
   "metadata": {},
   "source": [
    "## Non-Uniform Dropout Probability\n",
    "\n",
    "Testing the effect of varying the dropout probability across layers. \n",
    "\n",
    "Batch Size: 256\n",
    "\n",
    "Number of Dropout Layers: 3\n",
    "\n",
    "Number of BatchNorm Layers: 2\n",
    "\n",
    "Dropout Probability: [0.1, 0.2, 0.3]\n",
    "\n",
    "Data Augmentation: true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930c895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Model\n",
    "#Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = [0,0,0]):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[0])(x)\n",
    "        drp-=1\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[1])(x)\n",
    "        drp-=1\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[2])(x)\n",
    "        drp-=1\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = [0,0,0]):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[0])(x)\n",
    "        drp-=1\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[1])(x)\n",
    "        drp-=1\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=[0,0,0], num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "    input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    if bn_pooling:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[0])(x)\n",
    "        drp-=1\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob[1])(x)\n",
    "        drp-=1\n",
    "    x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ee7e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "        self.prev_loss = None\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            print(self.epoch, epoch)\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "            print('end', logs)\n",
    "            \n",
    "        self.epoch += 1\n",
    "#         if (self.prev_loss == None):\n",
    "#             self.prev_loss = logs['loss']\n",
    "#         else:\n",
    "#             delta = np.abs(logs['loss'] - self.prev_loss)\n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a200fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3a17fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_resnet_dataaug(model, xtrain, ytrain, xtest, ytest, model_name, m=0, convergence=False):\n",
    "  \n",
    "    EPOCHS = 500 if convergence else 100    \n",
    "    #EPOCHS=10\n",
    "    BATCH_SIZE= 256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 25 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    print('Fitting with BS ', BATCH_SIZE)\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20) if convergence else []\n",
    "    hist = model.fit_generator(\n",
    "      batch_generator(\n",
    "          xtrain,\n",
    "          ytrain,\n",
    "          m=m,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS, \n",
    "          augment=apply_mask\n",
    "      ),\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch=np.floor(xtrain.shape[0]/BATCH_SIZE),\n",
    "      verbose=VERBOSITY,\n",
    "      callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name), es]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c613699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID3, DPCONV3, DPPROB[0.1, 0.2, 0.3] with cutout regularization augmenting with 2 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9849753379821777, 'accuracy': 0.34402042627334595}\n",
      "Time to reach 0.87 accuracy: 353.8247067928314 s\n",
      "25 25\n",
      "end {'loss': 0.2959114611148834, 'accuracy': 0.8942908644676208}\n",
      "50 50\n",
      "end {'loss': 0.33701395988464355, 'accuracy': 0.885667085647583}\n",
      "75 75\n",
      "end {'loss': 0.08119558542966843, 'accuracy': 0.9720953702926636}\n",
      "100 100\n",
      "end {'loss': 0.06175059825181961, 'accuracy': 0.9788361191749573}\n",
      "125 125\n",
      "end {'loss': 0.04832686856389046, 'accuracy': 0.9833633899688721}\n",
      "150 150\n",
      "end {'loss': 0.03850960731506348, 'accuracy': 0.9867788553237915}\n",
      "175 175\n",
      "end {'loss': 0.03378571569919586, 'accuracy': 0.9882411956787109}\n",
      "200 200\n",
      "end {'loss': 0.027928432449698448, 'accuracy': 0.9903044700622559}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.3007 - accuracy: 0.7751\n",
      "Final accuracy 0.7750999927520752 reached in 3290.1112921237946\n"
     ]
    }
   ],
   "source": [
    "dp = 3\n",
    "prob = [0.1,0.2,0.3]\n",
    "bn = 2\n",
    "m=2\n",
    "\n",
    "print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images -- convergence'.format(bn, dp, dp, prob, m))\n",
    "model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}__convergence'.format(bn, dp, dp, prob, m)\n",
    "resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab78af9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 0.0274589154869318, 'accuracy': 0.990705132484436}\n",
      "Time to reach 0.87 accuracy: 21.379766941070557 s\n",
      "25 25\n",
      "end {'loss': 0.023547060787677765, 'accuracy': 0.9918569922447205}\n",
      "50 50\n",
      "end {'loss': 0.020078452304005623, 'accuracy': 0.9932191371917725}\n",
      "75 75\n",
      "end {'loss': 0.018917160108685493, 'accuracy': 0.9936298131942749}\n",
      "100 100\n",
      "end {'loss': 0.017210695892572403, 'accuracy': 0.9941005706787109}\n",
      "125 125\n",
      "end {'loss': 0.016712816432118416, 'accuracy': 0.9943810105323792}\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.4501 - accuracy: 0.7819\n",
      "Final accuracy 0.7818999886512756 reached in 2109.7273614406586\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check on Early Stopping\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d31b6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID3, DPCONV3, DPPROB[0.1, 0.2, 0.3] with cutout regularization augmenting with 8 images -- convergence\n",
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 1.9892884492874146, 'accuracy': 0.34222254157066345}\n",
      "Time to reach 0.87 accuracy: 706.7439835071564 s\n",
      "25 25\n",
      "end {'loss': 0.10552433878183365, 'accuracy': 0.9628405570983887}\n",
      "50 50\n",
      "end {'loss': 0.1645677089691162, 'accuracy': 0.9427208304405212}\n",
      "75 75\n",
      "end {'loss': 0.028589993715286255, 'accuracy': 0.990349531173706}\n",
      "100 100\n",
      "end {'loss': 0.019782431423664093, 'accuracy': 0.9932291507720947}\n",
      "125 125\n",
      "end {'loss': 0.01572389528155327, 'accuracy': 0.9947065114974976}\n",
      "150 150\n",
      "end {'loss': 0.010338203981518745, 'accuracy': 0.9964869022369385}\n",
      "175 175\n",
      "end {'loss': 0.010637978091835976, 'accuracy': 0.9964167475700378}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.5902 - accuracy: 0.7774\n",
      "Final accuracy 0.777400016784668 reached in 8916.544905424118\n"
     ]
    }
   ],
   "source": [
    "dp = 3\n",
    "prob = [0.1,0.2,0.3]\n",
    "bn = 2\n",
    "m=8\n",
    "\n",
    "print('Training BN{}, DPID{}, DPCONV{}, DPPROB{} with cutout regularization augmenting with {} images -- convergence'.format(bn, dp, dp, prob, m))\n",
    "model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}_cutout{}__convergence'.format(bn, dp, dp, prob, m)\n",
    "resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98916b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with BS  256\n",
      "0 0\n",
      "end {'loss': 0.01137738861143589, 'accuracy': 0.9963091015815735}\n",
      "Time to reach 0.87 accuracy: 55.01160931587219 s\n",
      "25 25\n",
      "end {'loss': 0.009120335802435875, 'accuracy': 0.9968299269676208}\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.7476 - accuracy: 0.7665\n",
      "Final accuracy 0.7664999961853027 reached in 1753.1628396511078\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check on Early Stopping\n",
    "tt, acc = fit_resnet_dataaug(resnet_model,x_train, y_train, x_test, y_test, model_name, m=m, convergence=True)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56720aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
