{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDLS Project\n",
    "\n",
    "# Effects of Regularization Techniques on Image Classification Tasks\n",
    "\n",
    "Dataset: Cifar10\n",
    "\n",
    "Model: ResNet50\n",
    "\n",
    "Batchnorm Layers: 2, 3\n",
    "\n",
    "Batch Size: 256\n",
    "\n",
    "Notebook to collect data using batchsize = 256. Used to compare the performance of Adaptive Gradient Clipping Techniques\n",
    "\n",
    "References:\n",
    "\n",
    "https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691\n",
    "\n",
    "https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import  Rectangle\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D,MaxPooling2D, Flatten,BatchNormalization, Dropout,ZeroPadding2D, AveragePooling2D, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Model\n",
    "#Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "    x = Activation(activations.relu)(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    if bn>0:\n",
    "        x = BatchNormalization()(x)\n",
    "        bn-=1\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=0, num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "    input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "    bn = num_batchnorm\n",
    "    drp = num_dropout\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    if bn_pooling:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "    x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    if drp>0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        drp-=1\n",
    "    x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "        self.epoch += 1\n",
    "        \n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit, evaluate and checkpoint\n",
    "def fit_resnet(model, xtrain, ytrain, xtest, ytest, model_name):\n",
    "  \n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE=256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 10 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    model.fit(\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=VERBOSITY,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name)]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN2, DPID0, DPCONV0, DPPROB0\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 2.4039 - accuracy: 0.6614\n",
      "Final accuracy 0.6614000201225281 reached in 739.5686771869659\n",
      "Training BN2, DPID1, DPCONV1, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 84.46076798439026 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.5741 - accuracy: 0.7509\n",
      "Final accuracy 0.7508999705314636 reached in 728.4942226409912\n",
      "Training BN2, DPID2, DPCONV2, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 130.88760042190552 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3792 - accuracy: 0.7586\n",
      "Final accuracy 0.7585999965667725 reached in 746.7530069351196\n",
      "Training BN2, DPID3, DPCONV3, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 135.1029691696167 s\n",
      "313/313 [==============================] - 4s 9ms/step - loss: 1.5167 - accuracy: 0.7451\n",
      "Final accuracy 0.7451000213623047 reached in 816.8732273578644\n"
     ]
    }
   ],
   "source": [
    "#BN=2, dropout_prob=0.2\n",
    "num_dropout = [0,1,2,3]\n",
    "for dp in num_dropout:\n",
    "    if dp:\n",
    "        prob=0.2\n",
    "        print('Training BN2, DPID{}, DPCONV{}, DPPROB{}'.format(dp, dp, prob))\n",
    "        model_name = 'model_256_bn_2_dpid_{}_dpconv_{}_dpprob_{}.pkl'.format(dp, dp, prob)\n",
    "        resnet_model = resnet50(num_batchnorm=2, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "        tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "            \n",
    "        print('Final accuracy {} reached in {}'.format(acc, tt))\n",
    "    else:\n",
    "        prob = 0\n",
    "        print('Training BN2, DPID{}, DPCONV{}, DPPROB{}'.format(dp, dp, prob))\n",
    "        model_name = 'model_256_bn_2_dpid_{}_dpconv_{}_dpprob_{}.pkl'.format(dp, dp, prob)\n",
    "        resnet_model = resnet50(num_batchnorm=2, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "        tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "            \n",
    "        print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN3, DPID0, DPCONV0, DPPROB0\n",
      "Time to reach 0.87 accuracy: 294.1397042274475 s\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 2.0097 - accuracy: 0.7091\n",
      "Final accuracy 0.7091000080108643 reached in 827.2737009525299\n",
      "Training BN3, DPID1, DPCONV1, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 364.3352873325348 s\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.8967 - accuracy: 0.7147\n",
      "Final accuracy 0.7146999835968018 reached in 840.2007429599762\n",
      "Training BN3, DPID2, DPCONV2, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 515.2273375988007 s\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.3130 - accuracy: 0.7390\n",
      "Final accuracy 0.7390000224113464 reached in 854.6738781929016\n",
      "Training BN3, DPID3, DPCONV3, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 538.9585971832275 s\n",
      "313/313 [==============================] - 4s 10ms/step - loss: 1.2638 - accuracy: 0.7583\n",
      "Final accuracy 0.7583000063896179 reached in 877.1752090454102\n"
     ]
    }
   ],
   "source": [
    "#BN=3, dropout_prob=0.2\n",
    "num_dropout = [0,1,2,3]\n",
    "for dp in num_dropout:\n",
    "    if dp:\n",
    "        prob=0.2\n",
    "        print('Training BN3, DPID{}, DPCONV{}, DPPROB{}'.format(dp, dp, prob))\n",
    "        model_name = 'model_256_bn_3_dpid_{}_dpconv_{}_dpprob_{}.pkl'.format(dp, dp, prob)\n",
    "        resnet_model = resnet50(num_batchnorm=3, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "        tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "            \n",
    "        print('Final accuracy {} reached in {}'.format(acc, tt))\n",
    "    else:\n",
    "        prob = 0\n",
    "        print('Training BN3, DPID{}, DPCONV{}, DPPROB{}'.format(dp, dp, prob))\n",
    "        model_name = 'model_256_bn_3_dpid_{}_dpconv_{}_dpprob_{}.pkl'.format(dp, dp, prob)\n",
    "        resnet_model = resnet50(num_batchnorm=3, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "        tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "            \n",
    "        print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
