{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qpyV-YZacZn"
   },
   "source": [
    "### ResNet50 Model\n",
    "\n",
    "References:\n",
    "\n",
    "https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691\n",
    "\n",
    "https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AdzdlCYNPKYq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import  Rectangle\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D,MaxPooling2D, Flatten,BatchNormalization, Dropout,ZeroPadding2D, AveragePooling2D, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VtrW6zJPaS7n"
   },
   "outputs": [],
   "source": [
    " #Removing all regularizers\n",
    "\n",
    "def res_identity(x, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "  x_skip = x # this will be used for addition with the residual block \n",
    "  f1, f2 = filters\n",
    "  bn = num_batchnorm\n",
    "  drp = num_dropout\n",
    "\n",
    "  #first block \n",
    "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "\n",
    "  #second block # bottleneck (but size kept same with padding)\n",
    "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "\n",
    "  # third block activation used after adding the input\n",
    "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "\n",
    "  # add the input \n",
    "  x = Add()([x, x_skip])\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "  return x\n",
    "\n",
    "def res_conv(x, s, filters, num_batchnorm = 0, num_dropout=0, dropout_prob = 0):\n",
    "  '''\n",
    "  here the input size changes''' \n",
    "  x_skip = x\n",
    "  f1, f2 = filters\n",
    "  bn = num_batchnorm\n",
    "  drp = num_dropout\n",
    "\n",
    "  # first block\n",
    "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
    "  # when s = 2 then it is like downsizing the feature map\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "\n",
    "  # second block\n",
    "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "  x = Activation(activations.relu)(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "\n",
    "  #third block\n",
    "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
    "  if bn>0:\n",
    "    x = BatchNormalization()(x)\n",
    "    bn-=1\n",
    "\n",
    "  # shortcut \n",
    "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
    "  x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "  # add \n",
    "  x = Add()([x, x_skip])\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "def resnet50(num_batchnorm = 0, bn_pooling = False, dropout_prob=0, num_dropout_conv = 0, num_dropout_id = 0, num_dropout=0):\n",
    "\n",
    "  input_im = Input(shape=(32, 32, 3)) # cifar 10 images size\n",
    "  x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "  bn = num_batchnorm\n",
    "  drp = num_dropout\n",
    "\n",
    "  # 1st stage\n",
    "  # here we perform maxpooling, see the figure above\n",
    "\n",
    "  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "  if bn_pooling:\n",
    "    x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "\n",
    "  #2nd stage \n",
    "  # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "  x = res_conv(x, s=1, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(64, 256),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "  # 3rd stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(128, 512),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "  # 4th stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(256, 1024),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "  # 5th stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_conv, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "  x = res_identity(x, filters=(512, 2048),num_batchnorm=bn, num_dropout = num_dropout_id, dropout_prob = dropout_prob)\n",
    "\n",
    "  # ends with average pooling and dense connection\n",
    "\n",
    "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "  x = Flatten()(x)\n",
    "  if drp>0:\n",
    "    x = Dropout(dropout_prob)(x)\n",
    "    drp-=1\n",
    "  x = Dense(10, activation='softmax')(x) #multi-class\n",
    "\n",
    "  # define the model \n",
    "\n",
    "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jbcZCB_IQoWX"
   },
   "outputs": [],
   "source": [
    "#to measure Time to Accuracy\n",
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "class timeToAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, startTime, epoch_ckpt, model_name):\n",
    "        super(timeToAccuracy, self).__init__()\n",
    "        self.targetAcc = 0.87 #CHANGE TO 0.87 WHEN RUNNING MODEL\n",
    "        self.foundTarget = False\n",
    "        self.startTime = startTime\n",
    "        self.epoch = 0\n",
    "        self.epoch_ckpt = epoch_ckpt\n",
    "        self.model_name = model_name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch % self.epoch_ckpt == 0:\n",
    "            name = self.model_name + '.h5'\n",
    "            self.model.save_weights(name)\n",
    "        self.epoch += 1\n",
    "        \n",
    "        if not self.foundTarget:\n",
    "            if logs['accuracy'] >= self.targetAcc:\n",
    "                current = time.time()\n",
    "                print(\"Time to reach {} accuracy: {} s\".format(self.targetAcc, current-self.startTime))\n",
    "                with open('{}_tta.pkl'.format(model_name), 'wb') as file:\n",
    "                    pickle.dump(current-self.startTime, file)\n",
    "                self.foundTarget = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PyU1rauccUbZ"
   },
   "outputs": [],
   "source": [
    "def fit_resnet(model, xtrain, ytrain, xtest, ytest, model_name):\n",
    "  \n",
    "    EPOCHS = 100      #Change to 200 when running the model\n",
    "    BATCH_SIZE= 256\n",
    "    VERBOSITY = 0   #Change to 0 when actually running model\n",
    "    EPOCH_CKPT = 10 # save model every N epochs\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=['accuracy'])\n",
    "    #fit the model\n",
    "    start = time.time()\n",
    "    print('Fitting with BS ', BATCH_SIZE)\n",
    "    model.fit(\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=VERBOSITY,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks=[timeToAccuracy(startTime=start, epoch_ckpt=EPOCH_CKPT, model_name=model_name)]\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    #evaluate\n",
    "    score = model.evaluate(xtest,ytest)\n",
    "    loss = score[0]\n",
    "    acc = score[1]\n",
    "\n",
    "    return train_time,  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWnAAeLrPGDW",
    "outputId": "e7d29675-e664-49a9-d668-9a97077ff9e8"
   },
   "outputs": [],
   "source": [
    "#prepare data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Data normalization\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_probabilities = [0.2,0.5,0.8]\n",
    "num_dropout = [1,2,3]\n",
    "num_batchnorm = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN1, DPID1, DPCONV1, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 372.54839181900024 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.6355 - accuracy: 0.7744\n",
      "Final accuracy 0.774399995803833 reached in 3829.346446990967\n",
      "Training BN1, DPID1, DPCONV1, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 589.5758216381073 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.2210 - accuracy: 0.7669\n",
      "Final accuracy 0.7669000029563904 reached in 3769.910964488983\n",
      "Training BN1, DPID1, DPCONV1, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 1491.6611511707306 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 2.3188 - accuracy: 0.5841\n",
      "Final accuracy 0.5841000080108643 reached in 3829.7431721687317\n",
      "Training BN1, DPID2, DPCONV1, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 425.7824034690857 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3371 - accuracy: 0.7658\n",
      "Final accuracy 0.7657999992370605 reached in 3866.098507165909\n",
      "Training BN1, DPID2, DPCONV1, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 881.6204488277435 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.0702 - accuracy: 0.7697\n",
      "Final accuracy 0.7696999907493591 reached in 3914.1877200603485\n",
      "Training BN1, DPID2, DPCONV1, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 2061.481954097748 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.6158 - accuracy: 0.6880\n",
      "Final accuracy 0.6880000233650208 reached in 4010.3561074733734\n",
      "Training BN1, DPID3, DPCONV1, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 440.9396069049835 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3044 - accuracy: 0.7679\n",
      "Final accuracy 0.7678999900817871 reached in 4025.7982246875763\n",
      "Training BN1, DPID3, DPCONV1, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 939.4056541919708 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.2605 - accuracy: 0.7563\n",
      "Final accuracy 0.7562999725341797 reached in 4012.3769273757935\n",
      "Training BN1, DPID3, DPCONV1, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 2330.820626974106 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.4169 - accuracy: 0.6886\n",
      "Final accuracy 0.6886000037193298 reached in 3946.7583363056183\n",
      "Training BN1, DPID1, DPCONV2, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 346.21084094047546 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.4921 - accuracy: 0.7740\n",
      "Final accuracy 0.7739999890327454 reached in 3825.6978917121887\n",
      "Training BN1, DPID1, DPCONV2, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 689.7009916305542 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3203 - accuracy: 0.7867\n",
      "Final accuracy 0.7867000102996826 reached in 3806.625495195389\n",
      "Training BN1, DPID1, DPCONV2, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 1489.590897321701 s\n",
      "313/313 [==============================] - 4s 8ms/step - loss: 1.6029 - accuracy: 0.7069\n",
      "Final accuracy 0.7069000005722046 reached in 3813.8370082378387\n",
      "Training BN1, DPID2, DPCONV2, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 490.61558651924133 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.1624 - accuracy: 0.7774\n",
      "Final accuracy 0.777400016784668 reached in 3894.92662525177\n",
      "Training BN1, DPID2, DPCONV2, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 1421.2157800197601 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.2897 - accuracy: 0.7254\n",
      "Final accuracy 0.7253999710083008 reached in 4029.6007809638977\n",
      "Training BN1, DPID2, DPCONV2, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 3661.485132932663 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.5032 - accuracy: 0.6201\n",
      "Final accuracy 0.6201000213623047 reached in 4298.549465894699\n",
      "Training BN1, DPID3, DPCONV2, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 662.7737510204315 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.1772 - accuracy: 0.7797\n",
      "Final accuracy 0.779699981212616 reached in 4193.669356107712\n",
      "Training BN1, DPID3, DPCONV2, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 1658.894428730011 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.2960 - accuracy: 0.7093\n",
      "Final accuracy 0.7092999815940857 reached in 4026.9567980766296\n",
      "Training BN1, DPID3, DPCONV2, DPPROB0.8\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.5977 - accuracy: 0.5660\n",
      "Final accuracy 0.5659999847412109 reached in 4032.6303894519806\n",
      "Training BN1, DPID1, DPCONV3, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 405.8577525615692 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.1522 - accuracy: 0.7515\n",
      "Final accuracy 0.7515000104904175 reached in 3856.3842883110046\n",
      "Training BN1, DPID1, DPCONV3, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 797.7212045192719 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3524 - accuracy: 0.7657\n",
      "Final accuracy 0.7656999826431274 reached in 3879.7061038017273\n",
      "Training BN1, DPID1, DPCONV3, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 1458.387258052826 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.4629 - accuracy: 0.7248\n",
      "Final accuracy 0.7247999906539917 reached in 3847.5011446475983\n",
      "Training BN1, DPID2, DPCONV3, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 530.6737008094788 s\n"
     ]
    }
   ],
   "source": [
    "#here is output with bs 64\n",
    "for dp_conv in num_dropout:\n",
    "    for dp_id in num_dropout:\n",
    "        for prob in dropout_probabilities:\n",
    "            print('Training BN1, DPID{}, DPCONV{}, DPPROB{}'.format(dp_id, dp_conv, prob))\n",
    "            model_name = 'model_bn1_dpid_{}_dpconv_{}_dpprob_{}'.format(dp_id, dp_conv, prob)\n",
    "            resnet_model = resnet50(num_batchnorm=1, bn_pooling=True, num_dropout_conv=dp_conv, num_dropout_id=dp_id, dropout_prob=prob)\n",
    "            tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "            \n",
    "            print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uQ7P6jEZvXV"
   },
   "outputs": [],
   "source": [
    "3+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN1, DPID2, DPCONV3, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 561.4235665798187 s\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 1.1866 - accuracy: 0.7800\n",
      "Final accuracy 0.7799999713897705 reached in 3987.347130537033\n",
      "Training BN1, DPID2, DPCONV3, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 1469.642249584198 s\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 1.1700 - accuracy: 0.7343\n",
      "Final accuracy 0.7343000173568726 reached in 3935.1762204170227\n",
      "Training BN1, DPID2, DPCONV3, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 3511.4251670837402 s\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 2.1035 - accuracy: 0.5344\n",
      "Final accuracy 0.5343999862670898 reached in 3899.4076869487762\n",
      "Training BN1, DPID3, DPCONV3, DPPROB0.2\n",
      "Time to reach 0.87 accuracy: 542.2596106529236 s\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 1.1328 - accuracy: 0.7867\n",
      "Final accuracy 0.7867000102996826 reached in 3988.3534348011017\n",
      "Training BN1, DPID3, DPCONV3, DPPROB0.5\n",
      "Time to reach 0.87 accuracy: 1618.7941226959229 s\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.2691 - accuracy: 0.7097\n",
      "Final accuracy 0.7096999883651733 reached in 3997.3226013183594\n",
      "Training BN1, DPID3, DPCONV3, DPPROB0.8\n",
      "Time to reach 0.87 accuracy: 3916.1720113754272 s\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 1.5780 - accuracy: 0.5781\n",
      "Final accuracy 0.5781000256538391 reached in 4058.1947960853577\n"
     ]
    }
   ],
   "source": [
    "for dp_id in [2,3]:\n",
    "    for prob in dropout_probabilities:\n",
    "        print('Training BN1, DPID{}, DPCONV{}, DPPROB{}'.format(dp_id, 3, prob))\n",
    "        model_name = 'model_bn1_dpid_{}_dpconv_{}_dpprob_{}'.format(dp_id, 3, prob)\n",
    "        resnet_model = resnet50(num_batchnorm=1, bn_pooling=True, num_dropout_conv=3, num_dropout_id=dp_id, dropout_prob=prob)\n",
    "        tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "\n",
    "        print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN1\n",
      "Time to reach 0.87 accuracy: 240.94208121299744 s\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 1.7229 - accuracy: 0.7506\n",
      "Final accuracy 0.7505999803543091 reached in 3654.2860102653503\n"
     ]
    }
   ],
   "source": [
    "print('Training BN1')\n",
    "model_name = 'model_bn1'\n",
    "resnet_model = resnet50(num_batchnorm=1, bn_pooling=True, num_dropout_conv=0, num_dropout_id=0)\n",
    "tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "\n",
    "print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN0, DPID0, DPCONV0, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 82.08244347572327 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.6214 - accuracy: 0.7084\n",
      "Final accuracy 0.7084000110626221 reached in 708.535605430603\n",
      "Training BN0, DPID1, DPCONV1, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 87.687912940979 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.5521 - accuracy: 0.7103\n",
      "Final accuracy 0.7103000283241272 reached in 705.064444065094\n",
      "Training BN0, DPID2, DPCONV2, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 118.21027135848999 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.5627 - accuracy: 0.6968\n",
      "Final accuracy 0.6967999935150146 reached in 716.3103256225586\n",
      "Training BN0, DPID3, DPCONV3, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 136.94057059288025 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.5812 - accuracy: 0.6814\n",
      "Final accuracy 0.6814000010490417 reached in 744.1642060279846\n"
     ]
    }
   ],
   "source": [
    "num_dropout = [0,1,2,3]\n",
    "for dp in num_dropout:\n",
    "    prob = 0.2\n",
    "    print('Training BN0, DPID{}, DPCONV{}, DPPROB{}'.format(dp, dp, prob))\n",
    "    model_name = 'model_bn0_dpid_{}_dpconv_{}_dpprob_{}'.format(dp, dp, prob)\n",
    "    resnet_model = resnet50(num_batchnorm=0, bn_pooling=False, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "    tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BN1, DPID0, DPCONV0, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 60.920347929000854 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.6886 - accuracy: 0.7211\n",
      "Final accuracy 0.7210999727249146 reached in 716.0166599750519\n",
      "Training BN1, DPID1, DPCONV1, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 76.42478275299072 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.5567 - accuracy: 0.7469\n",
      "Final accuracy 0.7469000220298767 reached in 734.286524772644\n",
      "Training BN1, DPID2, DPCONV2, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 115.41627550125122 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.2612 - accuracy: 0.7577\n",
      "Final accuracy 0.7577000260353088 reached in 743.4480056762695\n",
      "Training BN1, DPID3, DPCONV3, DPPROB0.2\n",
      "Fitting with BS  256\n",
      "Time to reach 0.87 accuracy: 119.08597731590271 s\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.2792 - accuracy: 0.7508\n",
      "Final accuracy 0.7508000135421753 reached in 767.3323245048523\n"
     ]
    }
   ],
   "source": [
    "for dp in num_dropout:\n",
    "    prob = 0.2\n",
    "    bn = 1\n",
    "    print('Training BN{}, DPID{}, DPCONV{}, DPPROB{}'.format(bn, dp, dp, prob))\n",
    "    model_name = 'model_bn{}_dpid_{}_dpconv_{}_dpprob_{}'.format(bn, dp, dp, prob)\n",
    "    resnet_model = resnet50(num_batchnorm=bn, bn_pooling=True, num_dropout_conv=dp, num_dropout_id=dp, dropout_prob=prob)\n",
    "    tt, acc = fit_resnet(resnet_model,x_train, y_train, x_test, y_test, model_name)\n",
    "\n",
    "    print('Final accuracy {} reached in {}'.format(acc, tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IDLS Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
